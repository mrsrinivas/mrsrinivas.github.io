<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Srinivas Reddy Alluri | Lead/Staff Data Analytics Engineer | Tech Lead</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Poppins:300,400,500,600,700&display=swap">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
  <style>
    body {
      font-family: 'Poppins', sans-serif;
      font-size: 16px;
      line-height: 1.5;
      padding: 20px;
      color: #333;
      background-color: #f9f9f9;
    }

    .resume-container {
      max-width: 800px;
      margin: 0 auto;
      padding: 10px;
      background-color: #fff;
      border-radius: 10px;
      font-size: 14px;
    }

    .resume-header {
      background-color: #fff;
      color: #000;
      padding: 10px;
      border-bottom: 1px solid #333;
      font-size: 18px;
      display: flex;
      flex-direction: column;
      align-items: center;
    }

    .resume-header h1 {
      font-size: 24px;
      margin: 0;
    }

    .resume-header h2 {
      font-size: 20px;
      margin: 0;
    }

    .resume-header .contact-info {
      margin-top: 5px;
      font-size: 14px;
    }

    .resume-header .contact-info a {
      color: #000;
      text-decoration: none;
      margin: 0 5px;
    }

    .resume-header .contact-info a:hover {
      text-decoration: underline;
    }

    .resume-section {
      padding: 10px 20px;
    }


    .resume-section table {
      width: 100%;
      border-collapse: collapse;
      margin-bottom: 20px;
    }

    .resume-section table, .resume-section th, .resume-section td {
      border: 1px solid #ddd;
    }

    .resume-section th, .resume-section td {
      padding: 8px;
      text-align: left;
    }

    .resume-section th {
      background-color: #f4f4f4;
      font-weight: bold;
    }

    .resume-section td i {
      margin-right: 5px;
    }

    .experience-table td {
      vertical-align: top;
    }

    .experience-table .title {
      font-weight: bold;
    }

    @media print {
      body {
        background-color: #fff;
        color: #000;
        padding: 5px;

      }

      .resume-container {
        background-color: #fff;
        color: #000;
      }

      .resume-header {
        margin-bottom: 5px;
      }

      .resume-section {
        margin-bottom: 10px;
      }

      .resume-section table {
        border: 1px solid #000;
      }

      .resume-section th, .resume-section td {
        padding: 5px;
        font-size: 12px;
      }
    }
  </style>
</head>
<body>
<div class="resume-container">
  <div class="resume-header">
    <h1>Srinivas Reddy Alluri</h1>
    <h2>Lead/Staff Data Analytics Engineer | Tech Lead</h2>
    <div class="contact-info">
      <a href="tel:+6582255712"><i class="fas fa-phone"></i> +65 82255712</a>
      | <a href="#"><i class="fas fa-envelope"></i> heysrini@outlook.com</a>
      | <a href="https://stackoverflow.com/users/1592191/mrsrinivas" target="_blank"><i
      class="fab fa-stack-overflow"></i> Stackoverflow</a>
      | <a href="https://mrsrinivas.com/" target="_blank"><i class="fas fa-globe"></i> Website</a>
    </div>
  </div>

  <div class="resume-section">
    <h2><i class="fas fa-user"></i> Summary</h2>
    <ul>
      <li><i class="fas fa-calendar-alt"></i> Accomplished Tech Lead with over a decade of experience in designing and
        developing data products and platforms for analytical consumers, adept in both cloud and on-premises
        environments.
      </li>
      <li><i class="fas fa-tools"></i> Highly skilled in leveraging and building frameworks with advanced technologies,
        including Apache Spark, Apache Kafka, AWS Cloud, Presto, ScyllaDB, and Airflow.
      </li>
      <li><i class="fas fa-tachometer-alt"></i> Proven expertise in managing high-scale data ingestion pipelines
        processing terabytes daily, meeting stringent SLAs, and developing petabyte-scale, multi-tenant cloud data
        platforms on AWS.
      </li>
      <li><i class="fas fa-users"></i> Demonstrated leadership in team management, project oversight, and mentorship,
        ensuring successful project delivery and fostering professional growth.
      </li>
      <li><i class="fas fa-flag-checkered"></i> Key Contributions:
        <ul>
          <li><i class="fas fa-trophy"></i> Ranked among the top 11 all-time contributors on StackOverflow for Apache
            Spark, Apache Hadoop, and Spark SQL.
          </li>
          <li><i class="fas fa-code-branch"></i> Made contributions to the Apache Kafka codebase, including
            Kafka CLI commands unification.
          </li>
          <li><i class="fas fa-share-alt"></i> Delivered impactful presentations on "Telemetry Data Management" @ Grab and
            "Apache Kafka Connect" @ DBS to external audiences.
          </li>
        </ul>
      </li>
    </ul>
  </div>


  <div class="resume-section">
    <h2><i class="fas fa-briefcase"></i> Experience</h2>
    <div class="experience-item">
      <h3><i class="fas fa-building"></i> Grab <span><i class="fas fa-map-marker-alt"></i> Singapore</span></h3>
      <p><i class="fas fa-calendar-alt"></i> Oct 2019 - Present | Tech Lead </p>

      <h4><i class="fas fa-trophy"></i> Achievements</h4>

      <ul>
        <li>Developed a robust event data quality check system at a scale of TBs per day, improving the accuracy of clickstream data across various event types.</li>
        <li>Created a standardized data consumption SDK, transforming unstructured clickstream data into a consistent schema for data consumers.</li>
        <li>Conceptualized and implemented a multi-tenant data platform for Grab's four subsidiaries and developed a modular AuthZ solution to streamline resource operations, optimize user authorization, and ensure effective multi-tenancy management across the Experimentation and Event Tracking platform.</li>
        <li>Successfully migrated a PBs scale cloud data lake from AWS to Azure with minimal disruption to downstream users.</li>
        <li>Reduced costs and improved experiment sample prediction speed by replacing traditional TBs scale data scan methods with HyperLogLog algorithms.</li>
        <li>Improved data pipeline cost efficiency by 50% through strategic cluster scaling, performance tuning, and optimized compression techniques.</li>
      </ul>

      <h4><i class="fas fa-tasks"></i> Day-to-Day Responsibilities</h4>
      <ul>
        <li> Lead and mentor a team of data and backend engineers to develop and
          operationalize data products and features, managing daily data volumes of approximately TB size and hundreds of 
          billion records.
        </li>
        <li> Create comprehensive documentation to propose solutions and ensure project
          execution, aligning with various stakeholders across departments.
        </li>
        <li> Conduct regular code and document reviews, maintaining high standards of
          quality and fostering continuous improvement within the team.
        </li>
      </ul>
    </div>

    <div class="experience-item">
      <h3><i class="fas fa-building"></i> Accenture <span><i class="fas fa-map-marker-alt"></i> Singapore</span></h3>
      <p><i class="fas fa-calendar-alt"></i> Feb 2017 - Oct 2019 | Lead Data/ML Engineer (Digital Data Consultant)</p>
      <div class="experience-achievements">
        <h4><i class="fas fa-trophy"></i> Achievements:</h4>
        <ul>
          <li>Implemented cell-level security enforcement on datasets within the DBS Bank ADA data lake platform using
            BlueTalon and Protegrity as part of the Enterprise Data Security Framework (EDSF) team.
          </li>
          <li>Architected and optimized data pipelines for the data lake platform, utilizing tools such as Airflow,
            Alluxio, Spark, YARN, Hive, Object Store, and Kafka.
          </li>
          <li>Established and integrated Kafka, Kafka Connect, and Schema Registry with the metadata system and
            implemented Kerberos authentication with Active Directory for the Enterprise Streaming Platform team.
          </li>
          <li>Developed and shared best practices, including code samples and documentation, to guide application teams
            in effectively utilizing platform tools.
          </li>
          <li>Led a successful migration project for Neilson, transitioning from on-premise systems to the Azure cloud
            environment by migrating legacy infrastructure to Docker, Azure Batch Services, Azure Blob Storage, and
            HDInsight.
          </li>
        </ul>
      </div>

    </div>

    <div class="experience-item">
      <h3><i class="fas fa-building"></i> Model N <span><i class="fas fa-map-marker-alt"></i> India</span></h3>
      <p><i class="fas fa-calendar-alt"></i> Jun 2016 - Jan 2017 | Senior Software Engineer</p>
      <div class="experience-achievements">
        <h4><i class="fas fa-trophy"></i> Achievements:</h4>
        <ul>
          <li>Written Hive Generic UDFs to implement customized functions in Spark SQL.</li>
          <li>Involved in setting up Hadoop cluster using Apache components for Dev and QA environments.</li>
          <li>Rewritten Oracle SQL to ANSI SQL compliant ANTLR v4 grammar utility.</li>
          <li>Tuned job performance using YARN Application Master and Spark History Server.</li>
          <li>Developed Spark applications for Government Pricing calculation and deployed them on EMR-YARN.</li>
          <li>Transformed data in S3 from CSV to Parquet using Spark SQL external tables.</li>
        </ul>
      </div>

    </div>


    <div class="experience-item">
      <h3><i class="fas fa-building"></i> Verizon <span><i class="fas fa-map-marker-alt"></i> India</span></h3>
      <p><i class="fas fa-calendar-alt"></i> Feb 2014 - Jun 2016 | Senior Software Engineer</p>
      <div class="experience-achievements">
        <h4><i class="fas fa-trophy"></i> Achievements:</h4>
        <ul>
          <li>Designed and implemented MapReduce and Spark jobs to analyze end-user authentication and usage patterns.
          </li>
          <li>Improved QR code authentication performance by 60% using binary optimization techniques.</li>
          <li>Deployed an API monitoring portal using the Splunk engine and REST API</li>
          <li>Utilized the Oozie workflow engine to manage interdependent and automated job sequences.</li>
          <li>Developed a processing engine with Spark for the Telephone Denial of Service protection module.</li>
          <li>Managed data ingestion from various sources, overseeing HDFS maintenance and the loading of structured and
            unstructured data using Sqoop and Flume.
          </li>
        </ul>
      </div>
    </div>


    <div class="experience-item">
      <h3><i class="fas fa-building"></i> Tech4sys <span><i class="fas fa-map-marker-alt"></i> India</span>
      </h3>
      <p><i class="fas fa-calendar-alt"></i> May 2011 - Jan 2014 | Software Engineer</p>
      <div class="experience-achievements">
        <h4><i class="fas fa-trophy"></i> Achievements:</h4>
        <ul>
          <li>Designed and architected a job portal (JobCoconut), ensuring robust database design and functionality.
          </li>
          <li>Integrated payment gateways for Maventus and Planlab applications, enhancing transactional capabilities.
          </li>
          <li>Worked with Facebook Graph API and Twitter API to enable multimedia content posting through Maventus.</li>
          <li>Implemented social networking authentication (Facebook, Google, Twitter, LinkedIn) for e-commerce and job
            portal applications.
          </li>
          <li>Participated in all phases of software development, from application design through to deployment.</li>
          <li>Programmed in Java and PHP with an emphasis on object-oriented programming, focusing on code abstraction
            and reuse.
          </li>
        </ul>
      </div>
    </div>
  </div>

  
  <div class="resume-section">
    <h2><i class="fas fa-laptop-code"></i> Technical Skills</h2>
    <table>
      <thead>
        <tr>
          <th>Category</th>
          <th>Details</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><i class="fas fa-database"></i> Datastores</td>
          <td>S3, ScyllaDB, StarRocks, DynamoDB, MySQL, PostgreSQL</td>
        </tr>
        <tr>
          <td><i class="fas fa-tools"></i> Data tools and frameworks</td>
          <td>Apache Spark, Apache Kafka, Airflow, MLflow, Superset, Hadoop</td>
        </tr>
        <tr>
          <td><i class="fas fa-lock"></i> APIs</td>
          <td>RESTful APIs, gRPC</td>
        </tr>
        <tr>
          <td><i class="fas fa-cogs"></i> DevOps and Infrastructure</td>
          <td>AWS, Terraform, Kubernetes, Docker, Gitlab, Azure</td>
        </tr>
        <tr>
          <td><i class="fas fa-code"></i> Programming languages</td>
          <td>Python, Java, Scala, Go</td>
        </tr>
      </tbody>
    </table>
  </div>

  <div class="resume-section">
    <h2><i class="fas fa-graduation-cap"></i>Academics</h2>
    <ul>
      <li>Masters in Software Engineering – NUS, Singapore</li>
      <li>Bachelors in Computer Science Engineering – JNTU Hyderabad, India</li>
    </ul>
  </div>

  <div class="resume-section">
    <h2><i class="fas fa-certificate"></i> Certifications & Independent Courses</h2>
    <ul>
      <li> AWS Certified Machine Learning Specialty – Amazon Web Services</li>
      <li> Certified Developer on Apache Spark – Databricks and O'Reilly</li>
      <li> S201: Data Modeling and Application Development</li>
      <li> Functional Programming Principles in Scala – Coursera</li>
      <li> M101J: MongoDB for Java Developers – MongoDB University</li>
      <li> Certified Java Developer for J2SE-6.0 – Oracle</li>
    </ul>
  </div>
  
</div>
</body>
</html>
